{"cells":[{"cell_type":"markdown","metadata":{"id":"pfa39F4lsLf3"},"source":["<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## LSTM Bot QA"]},{"cell_type":"markdown","metadata":{"id":"ZqO0PRcFsPTe"},"source":["### Datos\n","El objecto es utilizar datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en inglés. Se construirá un BOT para responder a preguntas del usuario (QA).\\\n","[LINK](http://convai.io/data/)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"bDFC0I3j9oFD","executionInfo":{"status":"ok","timestamp":1723138135332,"user_tz":180,"elapsed":10666,"user":{"displayName":"Sevann Radhak T","userId":"02491188174489558861"}}},"outputs":[],"source":["!pip install --upgrade --no-cache-dir gdown --quiet"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"cq3YXak9sGHd","executionInfo":{"status":"ok","timestamp":1723138144890,"user_tz":180,"elapsed":6975,"user":{"displayName":"Sevann Radhak T","userId":"02491188174489558861"}}},"outputs":[],"source":["import re\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n","from sklearn.model_selection import train_test_split\n","import os\n","import gdown\n","import json"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RHNkUaPp6aYq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723138150187,"user_tz":180,"elapsed":343,"user":{"displayName":"Sevann Radhak T","userId":"02491188174489558861"}},"outputId":"a3ef4d3d-a188-421f-f9c7-51286b858918"},"outputs":[{"output_type":"stream","name":"stdout","text":["El dataset ya se encuentra descargado\n"]}],"source":["# Descargar la carpeta de dataset\n","if os.access('data_volunteers.json', os.F_OK) is False:\n","    url = 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download'\n","    output = 'data_volunteers.json'\n","    gdown.download(url, output, quiet=False)\n","else:\n","    print(\"El dataset ya se encuentra descargado\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"WZy1-wgG-Rp7","executionInfo":{"status":"ok","timestamp":1723138167624,"user_tz":180,"elapsed":393,"user":{"displayName":"Sevann Radhak T","userId":"02491188174489558861"}}},"outputs":[],"source":["# dataset_file\n","text_file = \"data_volunteers.json\"\n","with open(text_file) as f:\n","    data = json.load(f) # la variable data será un diccionario"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ue5qd54S-eew","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723138170475,"user_tz":180,"elapsed":327,"user":{"displayName":"Sevann Radhak T","userId":"02491188174489558861"}},"outputId":"3d9bb53d-75e9-4785-e7e6-3b51e6f7b604"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['dialog', 'start_time', 'end_time', 'bot_profile', 'user_profile', 'eval_score', 'profile_match', 'participant1_id', 'participant2_id'])"]},"metadata":{},"execution_count":6}],"source":["# Observar los campos disponibles en cada linea del dataset\n","data[0].keys()"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"jHBRAXPl-3dz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723138184298,"user_tz":180,"elapsed":511,"user":{"displayName":"Sevann Radhak T","userId":"02491188174489558861"}},"outputId":"b0f5b381-9443-46a5-a696-50dd8c380747"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cantidad de rows utilizadas: 6033\n"]}],"source":["chat_in = []\n","chat_out = []\n","input_sentences = []\n","output_sentences = []\n","output_sentences_inputs = []\n","max_len = 30\n","\n","def clean_text(txt):\n","    txt = txt.lower()\n","    txt.replace(\"\\'d\", \" had\")\n","    txt.replace(\"\\'s\", \" is\")\n","    txt.replace(\"\\'m\", \" am\")\n","    txt.replace(\"don't\", \"do not\")\n","    txt = re.sub(r'\\W+', ' ', txt)\n","\n","    return txt\n","\n","for line in data:\n","    for i in range(len(line['dialog'])-1):\n","        # vamos separando el texto en \"preguntas\" (chat_in)\n","        # y \"respuestas\" (chat_out)\n","        chat_in = clean_text(line['dialog'][i]['text'])\n","        chat_out = clean_text(line['dialog'][i+1]['text'])\n","\n","        if len(chat_in) >= max_len or len(chat_out) >= max_len:\n","            continue\n","\n","        input_sentence, output = chat_in, chat_out\n","\n","        # output sentence (decoder_output) tiene <eos>\n","        output_sentence = output + ' <eos>'\n","        # output sentence input (decoder_input) tiene <sos>\n","        output_sentence_input = '<sos> ' + output\n","\n","        input_sentences.append(input_sentence)\n","        output_sentences.append(output_sentence)\n","        output_sentences_inputs.append(output_sentence_input)\n","\n","print(\"Cantidad de rows utilizadas:\", len(input_sentences))"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"07L1qj8pC_l6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723138191366,"user_tz":180,"elapsed":355,"user":{"displayName":"Sevann Radhak T","userId":"02491188174489558861"}},"outputId":"3cf7486f-145f-47da-bbc2-1b454966dd0b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('hi how are you ', 'not bad and you  <eos>', '<sos> not bad and you ')"]},"metadata":{},"execution_count":8}],"source":["input_sentences[1], output_sentences[1], output_sentences_inputs[1]"]},{"cell_type":"markdown","metadata":{"id":"8P-ynUNP5xp6"},"source":["### 2 - Preprocesamiento\n","Realizar el preprocesamiento necesario para obtener:\n","- word2idx_inputs, max_input_len\n","- word2idx_outputs, max_out_len, num_words_output\n","- encoder_input_sequences, decoder_output_sequences, decoder_targets"]},{"cell_type":"markdown","source":["2.1: Tokenización y Creación de Diccionarios"],"metadata":{"id":"TLciIEvO95hU"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","MAX_VOCAB_SIZE = 8000\n","MAX_SEQUENCE_LENGTH = 10\n","\n","# Tokenizador para las entradas (preguntas)\n","tokenizer_inputs = Tokenizer(num_words=MAX_VOCAB_SIZE)\n","tokenizer_inputs.fit_on_texts(input_sentences)\n","input_sequences = tokenizer_inputs.texts_to_sequences(input_sentences)\n","\n","# Diccionario palabra a índice\n","word2idx_inputs = tokenizer_inputs.word_index\n","print(f\"Total de palabras en el vocabulario de entrada: {len(word2idx_inputs)}\")\n","\n","# Longitud máxima de entrada\n","max_input_len = max(len(s) for s in input_sequences)\n","print(f\"Longitud máxima de secuencia de entrada: {max_input_len}\")\n","\n","# Tokenizador para las salidas (respuestas)\n","tokenizer_outputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n","tokenizer_outputs.fit_on_texts(output_sentences + output_sentences_inputs)\n","output_sequences = tokenizer_outputs.texts_to_sequences(output_sentences)\n","output_sequences_inputs = tokenizer_outputs.texts_to_sequences(output_sentences_inputs)\n","\n","# Diccionario palabra a índice para las salidas\n","word2idx_outputs = tokenizer_outputs.word_index\n","num_words_output = len(word2idx_outputs) + 1\n","print(f\"Total de palabras en el vocabulario de salida: {num_words_output}\")\n","\n","# Longitud máxima de salida\n","max_out_len = max(len(s) for s in output_sequences)\n","print(f\"Longitud máxima de secuencia de salida: {max_out_len}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uq9n1WAg9wTy","executionInfo":{"status":"ok","timestamp":1723138289228,"user_tz":180,"elapsed":924,"user":{"displayName":"Sevann Radhak T","userId":"02491188174489558861"}},"outputId":"ebea4a7e-0e37-48ea-d521-56e384c6c30a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Total de palabras en el vocabulario de entrada: 1799\n","Longitud máxima de secuencia de entrada: 9\n","Total de palabras en el vocabulario de salida: 1807\n","Longitud máxima de secuencia de salida: 10\n"]}]},{"cell_type":"markdown","source":["2.2: Padding de Secuencias"],"metadata":{"id":"A0EqJVCN99MB"}},{"cell_type":"code","source":["encoder_input_sequences = pad_sequences(input_sequences, maxlen=max_input_len)\n","decoder_input_sequences = pad_sequences(output_sequences_inputs, maxlen=max_out_len)\n","decoder_output_sequences = pad_sequences(output_sequences, maxlen=max_out_len)"],"metadata":{"id":"Y9JK4hp39-r5","executionInfo":{"status":"ok","timestamp":1723138297576,"user_tz":180,"elapsed":429,"user":{"displayName":"Sevann Radhak T","userId":"02491188174489558861"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_CJIsLBbj6rg"},"source":["### 3 - Preparar los embeddings\n","Utilizar los embeddings de Glove o FastText para transformar los tokens de entrada en vectores"]},{"cell_type":"code","source":["!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n","!gunzip cc.en.300.vec.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83mWIXfL-6_W","executionInfo":{"status":"ok","timestamp":1723138546693,"user_tz":180,"elapsed":242077,"user":{"displayName":"Sevann Radhak T","userId":"02491188174489558861"}},"outputId":"775dcbb0-3aa0-471c-e8fa-811a6e657b5d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-08-08 17:31:45--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.65.229.46, 18.65.229.89, 18.65.229.121, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.65.229.46|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1325960915 (1.2G) [binary/octet-stream]\n","Saving to: ‘cc.en.300.vec.gz’\n","\n","cc.en.300.vec.gz    100%[===================>]   1.23G   150MB/s    in 6.7s    \n","\n","2024-08-08 17:31:51 (188 MB/s) - ‘cc.en.300.vec.gz’ saved [1325960915/1325960915]\n","\n","gzip: cc.en.300.vec already exists; do you wish to overwrite (y or n)? y\n","y\n","yes\n","exit\n"]}]},{"cell_type":"code","source":["EMBEDDING_DIM = 300\n","embedding_file = 'cc.en.300.vec'\n","embedding_matrix = np.zeros((len(word2idx_inputs) + 1, EMBEDDING_DIM))\n","\n","# Cargar los embeddings de FastText\n","with open(embedding_file, 'r', encoding='utf-8') as f:\n","    for line in f:\n","        values = line.split()\n","        word = values[0]\n","        vector = np.asarray(values[1:], dtype='float32')\n","        if word in word2idx_inputs:\n","            idx = word2idx_inputs[word]\n","            embedding_matrix[idx] = vector\n","\n","\n","embedding_layer = Embedding(\n","    len(word2idx_inputs) + 1,\n","    EMBEDDING_DIM,\n","    weights=[embedding_matrix],\n","    input_length=max_input_len,\n","    trainable=False\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YXOQDA-_-FGu","executionInfo":{"status":"ok","timestamp":1723138792339,"user_tz":180,"elapsed":153999,"user":{"displayName":"Sevann Radhak T","userId":"02491188174489558861"}},"outputId":"e875613a-93d7-487c-f7a2-10f8e88883d3"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["encoder_inputs = Input(shape=(max_input_len,))\n","x = embedding_layer(encoder_inputs)\n","encoder_lstm = LSTM(128, return_state=True, dropout=0.2)\n","encoder_outputs, state_h, state_c = encoder_lstm(x)\n","encoder_states = [state_h, state_c]\n","\n","decoder_inputs = Input(shape=(max_out_len,))\n","decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n","decoder_embedding = decoder_embedding(decoder_inputs)\n","\n","decoder_lstm = LSTM(128, return_sequences=True, return_state=True, dropout=0.2)\n","decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n","decoder_dense = Dense(num_words_output, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"q1sUQgTLB0FT","executionInfo":{"status":"ok","timestamp":1723138822760,"user_tz":180,"elapsed":1222,"user":{"displayName":"Sevann Radhak T","userId":"02491188174489558861"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3vKbhjtIwPgM"},"source":["### 4 - Entrenar el modelo\n","Entrenar un modelo basado en el esquema encoder-decoder utilizando los datos generados en los puntos anteriores. Utilce como referencias los ejemplos vistos en clase."]},{"cell_type":"code","source":["decoder_target_data = np.expand_dims(decoder_output_sequences, -1)\n","r = model.fit(\n","    [encoder_input_sequences, decoder_input_sequences],\n","    decoder_target_data,\n","    batch_size=64,\n","    epochs=50,\n","    validation_split=0.2\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NlniKQKrB70r","executionInfo":{"status":"ok","timestamp":1723138912989,"user_tz":180,"elapsed":78694,"user":{"displayName":"Sevann Radhak T","userId":"02491188174489558861"}},"outputId":"88a6e972-3154-4be2-d69c-e8cba0758654"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.4682 - loss: 4.6087 - val_accuracy: 0.6083 - val_loss: 2.3649\n","Epoch 2/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.6022 - loss: 2.2474 - val_accuracy: 0.6476 - val_loss: 2.1646\n","Epoch 3/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6419 - loss: 2.0410 - val_accuracy: 0.6661 - val_loss: 2.0274\n","Epoch 4/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6596 - loss: 1.9038 - val_accuracy: 0.6738 - val_loss: 1.9357\n","Epoch 5/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6795 - loss: 1.7843 - val_accuracy: 0.6879 - val_loss: 1.8599\n","Epoch 6/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6984 - loss: 1.6773 - val_accuracy: 0.6965 - val_loss: 1.7792\n","Epoch 7/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7088 - loss: 1.6109 - val_accuracy: 0.7004 - val_loss: 1.7417\n","Epoch 8/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7228 - loss: 1.5331 - val_accuracy: 0.7035 - val_loss: 1.7165\n","Epoch 9/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7244 - loss: 1.5007 - val_accuracy: 0.7121 - val_loss: 1.6659\n","Epoch 10/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7325 - loss: 1.4533 - val_accuracy: 0.7154 - val_loss: 1.6342\n","Epoch 11/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7389 - loss: 1.4173 - val_accuracy: 0.7188 - val_loss: 1.6152\n","Epoch 12/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7442 - loss: 1.3755 - val_accuracy: 0.7219 - val_loss: 1.5974\n","Epoch 13/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7474 - loss: 1.3639 - val_accuracy: 0.7241 - val_loss: 1.5799\n","Epoch 14/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7456 - loss: 1.3489 - val_accuracy: 0.7239 - val_loss: 1.5709\n","Epoch 15/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7490 - loss: 1.3415 - val_accuracy: 0.7264 - val_loss: 1.5485\n","Epoch 16/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7530 - loss: 1.3123 - val_accuracy: 0.7241 - val_loss: 1.5379\n","Epoch 17/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7539 - loss: 1.3103 - val_accuracy: 0.7300 - val_loss: 1.5220\n","Epoch 18/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7591 - loss: 1.2675 - val_accuracy: 0.7292 - val_loss: 1.5128\n","Epoch 19/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7590 - loss: 1.2674 - val_accuracy: 0.7351 - val_loss: 1.5009\n","Epoch 20/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7663 - loss: 1.2422 - val_accuracy: 0.7345 - val_loss: 1.4949\n","Epoch 21/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7653 - loss: 1.2529 - val_accuracy: 0.7403 - val_loss: 1.4806\n","Epoch 22/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7682 - loss: 1.2247 - val_accuracy: 0.7408 - val_loss: 1.4714\n","Epoch 23/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7707 - loss: 1.2084 - val_accuracy: 0.7413 - val_loss: 1.4646\n","Epoch 24/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7686 - loss: 1.2145 - val_accuracy: 0.7428 - val_loss: 1.4575\n","Epoch 25/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7712 - loss: 1.2077 - val_accuracy: 0.7450 - val_loss: 1.4505\n","Epoch 26/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7729 - loss: 1.1947 - val_accuracy: 0.7452 - val_loss: 1.4437\n","Epoch 27/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7760 - loss: 1.1739 - val_accuracy: 0.7447 - val_loss: 1.4395\n","Epoch 28/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7765 - loss: 1.1695 - val_accuracy: 0.7418 - val_loss: 1.4364\n","Epoch 29/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7740 - loss: 1.1743 - val_accuracy: 0.7476 - val_loss: 1.4305\n","Epoch 30/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7803 - loss: 1.1425 - val_accuracy: 0.7511 - val_loss: 1.4199\n","Epoch 31/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7794 - loss: 1.1433 - val_accuracy: 0.7506 - val_loss: 1.4142\n","Epoch 32/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7851 - loss: 1.1165 - val_accuracy: 0.7510 - val_loss: 1.4072\n","Epoch 33/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7803 - loss: 1.1338 - val_accuracy: 0.7521 - val_loss: 1.4053\n","Epoch 34/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7831 - loss: 1.1132 - val_accuracy: 0.7511 - val_loss: 1.4042\n","Epoch 35/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7870 - loss: 1.1030 - val_accuracy: 0.7540 - val_loss: 1.3979\n","Epoch 36/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7843 - loss: 1.0957 - val_accuracy: 0.7534 - val_loss: 1.4010\n","Epoch 37/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7837 - loss: 1.1010 - val_accuracy: 0.7532 - val_loss: 1.3933\n","Epoch 38/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7866 - loss: 1.0970 - val_accuracy: 0.7534 - val_loss: 1.3907\n","Epoch 39/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7868 - loss: 1.0861 - val_accuracy: 0.7568 - val_loss: 1.3856\n","Epoch 40/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7899 - loss: 1.0798 - val_accuracy: 0.7534 - val_loss: 1.3870\n","Epoch 41/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7866 - loss: 1.0766 - val_accuracy: 0.7578 - val_loss: 1.3762\n","Epoch 42/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7878 - loss: 1.0780 - val_accuracy: 0.7567 - val_loss: 1.3801\n","Epoch 43/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7907 - loss: 1.0600 - val_accuracy: 0.7553 - val_loss: 1.3757\n","Epoch 44/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7903 - loss: 1.0609 - val_accuracy: 0.7546 - val_loss: 1.3752\n","Epoch 45/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7900 - loss: 1.0567 - val_accuracy: 0.7592 - val_loss: 1.3690\n","Epoch 46/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7939 - loss: 1.0281 - val_accuracy: 0.7598 - val_loss: 1.3666\n","Epoch 47/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7946 - loss: 1.0222 - val_accuracy: 0.7603 - val_loss: 1.3620\n","Epoch 48/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7939 - loss: 1.0360 - val_accuracy: 0.7604 - val_loss: 1.3609\n","Epoch 49/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7925 - loss: 1.0352 - val_accuracy: 0.7605 - val_loss: 1.3614\n","Epoch 50/50\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7981 - loss: 1.0089 - val_accuracy: 0.7582 - val_loss: 1.3633\n"]}]},{"cell_type":"markdown","metadata":{"id":"Zbwn0ekDy_s2"},"source":["### 5 - Inferencia\n","Experimentar el funcionamiento de su modelo. Recuerde que debe realizar la inferencia de los modelos por separado de encoder y decoder."]},{"cell_type":"code","source":["encoder_model = Model(encoder_inputs, encoder_states)\n","\n","decoder_state_input_h = Input(shape=(128,))\n","decoder_state_input_c = Input(shape=(128,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","decoder_outputs, state_h, state_c = decoder_lstm(\n","    decoder_embedding, initial_state=decoder_states_inputs)\n","\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states\n",")\n","\n","reverse_word_map = dict(map(reversed, word2idx_outputs.items()))\n","\n","# Función de Decodificación\n","def decode_sequence(input_seq):\n","    states_value = encoder_model.predict(input_seq)\n","\n","    target_seq = np.zeros((1, 1))\n","    target_seq[0, 0] = word2idx_outputs['<sos>']\n","\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_word = reverse_word_map[sampled_token_index]\n","\n","        if sampled_word == '<eos>' or len(decoded_sentence.split()) > max_out_len:\n","            stop_condition = True\n","        else:\n","            decoded_sentence += ' ' + sampled_word\n","\n","        target_seq = np.zeros((1, 1))\n","        target_seq[0, 0] = sampled_token_index\n","\n","        states_value = [h, c]\n","\n","    return decoded_sentence.strip()\n","\n","# Probar el BOT con preguntas\n","questions = [\"do you read?\", \"do you have any pet?\", \"where are you from?\"]\n","for question in questions:\n","    input_seq = tokenizer_inputs.texts_to_sequences([question])\n","    input_seq = pad_sequences(input_seq, maxlen=max_input_len)\n","    decoded_answer = decode_sequence(input_seq)\n","    print(f'Q: {question}\\nA: {decoded_answer}\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C6zs35sOA0ws","executionInfo":{"status":"ok","timestamp":1723139109698,"user_tz":180,"elapsed":4414,"user":{"displayName":"Sevann Radhak T","userId":"02491188174489558861"}},"outputId":"0410698c-de08-4b8a-8fa0-f060ad3e5dfb"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","Q: do you read?\n","A: what do you do for a living for a living\n","\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Q: do you have any pet?\n","A: what do you do for a living for fun\n","\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","Q: where are you from?\n","A: what do you do for a living for fun\n","\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.6"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}